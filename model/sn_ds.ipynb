{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"../datasets/ESD_score_list.csv\")\n",
    "# df.columns = [\"path\", \"score\"]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle as pk\n",
    "import os\n",
    "\n",
    "\n",
    "class EsdStrengthDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx][\"path\"]\n",
    "        score = self.df.iloc[idx][\"score\"]\n",
    "        emotion = self.df.iloc[idx][\"emotion\"]\n",
    "        emotion_id = self.df.iloc[idx][\"emotion_id\"]\n",
    "        mel_path = self.df.iloc[idx][\"mel_path\"]\n",
    "        \n",
    "        with open(mel_path, \"rb\") as f:\n",
    "            mel = pk.load(f)\n",
    "        \n",
    "        return {\n",
    "            \"path\": path,\n",
    "            \"score\": score,\n",
    "            \"emotion\": emotion,\n",
    "            \"emotion_id\": emotion_id,\n",
    "            \"mel\": mel,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_mel_path_from_audio_path(audio_path, preprocessed_basedir):\n",
    "        basename = audio_path.split(\"/\")[-1].replace(\".wav\", \"\") + \"_\" + audio_path.split(\"/\")[-2].lower()\n",
    "        return f\"{preprocessed_basedir}/mel/mel_{basename}.pkl\"\n",
    "    \n",
    "    @classmethod\n",
    "    def from_csv(cls, path, emotion2idx, preprocessed_basedir, val_speakers, **kwargs):\n",
    "        df = pd.read_csv(path)\n",
    "        df.columns = [\"path\", \"score\"]\n",
    "        \n",
    "        # drop rows without mel file\n",
    "        df[\"mel_path\"] = df[\"path\"].apply(lambda x: cls.get_mel_path_from_audio_path(x, preprocessed_basedir))\n",
    "        df = df[df[\"mel_path\"].apply(lambda x: os.path.exists(x))]\n",
    "        \n",
    "        df[\"emotion\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-2].lower())\n",
    "        df[\"emotion_id\"] = df[\"emotion\"].apply(lambda x: emotion2idx[x])\n",
    "        \n",
    "        df[\"speaker\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-3])\n",
    "        \n",
    "        print(\"Loaded dataset with\", len(df), \"samples\")\n",
    "        \n",
    "        # train test split\n",
    "        val_df = df[df[\"speaker\"].isin(val_speakers)]\n",
    "        train_df = df[~df[\"speaker\"].isin(val_speakers)]\n",
    "        print(\"Train samples:\", len(train_df))\n",
    "        print(\"Val samples:\", len(val_df))\n",
    "\n",
    "        # reset index\n",
    "        val_df = val_df.reset_index(drop=True)\n",
    "        train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "        return cls(train_df, **kwargs), cls(val_df, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 14597 samples\n",
      "Train samples: 12249\n",
      "Val samples: 2348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'path': '0012/Angry/0012_000351.wav',\n",
       " 'score': 0.52011,\n",
       " 'emotion': 'angry',\n",
       " 'emotion_id': 0,\n",
       " 'mel': array([[ -5.891084 ,  -7.9609103,  -6.724277 , ..., -11.107079 ,\n",
       "         -11.025017 , -10.827656 ],\n",
       "        [ -5.492388 ,  -7.182169 ,  -7.0519705, ..., -11.132161 ,\n",
       "         -11.4717655, -11.510298 ],\n",
       "        [ -5.143411 ,  -7.0178847,  -8.056166 , ..., -11.138936 ,\n",
       "         -11.512925 , -11.512925 ],\n",
       "        ...,\n",
       "        [ -5.949753 ,  -7.2775326,  -7.0753965, ..., -11.334373 ,\n",
       "         -11.512925 , -11.512925 ],\n",
       "        [ -5.7215767,  -6.2575912,  -6.301642 , ...,  -9.436365 ,\n",
       "          -9.496191 ,  -9.729062 ],\n",
       "        [ -5.091888 ,  -5.370623 ,  -5.3995743, ...,  -8.487104 ,\n",
       "          -8.542133 ,  -8.772532 ]], dtype=float32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2id = {\n",
    "    \"angry\": 0,\n",
    "    \"happy\": 1,\n",
    "    \"neutral\": 2,\n",
    "    \"sad\": 3,\n",
    "    \"surprise\": 4,\n",
    "}\n",
    "\n",
    "train_ds, val_ds = EsdStrengthDataset.from_csv(\"../datasets/ESD_score_list_all.csv\", emotion2idx=e2id, preprocessed_basedir=\"../datasets/esd_processed\", val_speakers={\"0001\", \"0005\", \"0011\", \"0015\"})\n",
    "\n",
    "train_ds[0]\n",
    "# train_ds.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12249"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math \n",
    "from torch.functional import F\n",
    "\n",
    "\n",
    "def mixup_data(x_emo, x_neu, alpha=1.0, lam=None):\n",
    "    \"\"\"Applies mixup augmentation to the data.\n",
    "\n",
    "    Args:\n",
    "    x_emo (Tensor): Input data (e.g., features of speech samples).\n",
    "    x_neu (Tensor): Input data (e.g., features of speech samples).\n",
    "\n",
    "    Returns:\n",
    "    mixed_x (Tensor): The mixed input data.\n",
    "    lam (float): The mixup coefficient.\n",
    "    \"\"\"\n",
    "    if lam is None:\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "\n",
    "    x_mixed = lam * x_emo + (1 - lam) * x_neu\n",
    "\n",
    "    return x_mixed, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(pred, y_emo, y_neu, lam) -> torch.Tensor:\n",
    "    w_emo = math.sqrt(1)\n",
    "    w_neu = math.sqrt(1)\n",
    "    l_emo = sum([F.cross_entropy(pred[i], y_emo[i]) * lam[i] for i in range(len(pred))]) / len(pred)\n",
    "    l_neu = sum([F.cross_entropy(pred[i], y_neu[i]) * (1 - lam[i]) for i in range(len(pred))]) / len(pred)\n",
    "    \n",
    "    loss = (w_emo * l_emo + w_neu * l_neu) / (w_emo + w_neu)\n",
    "    return torch.mean(loss)\n",
    "\n",
    "\n",
    "def rank_loss(ri, rj, lam_diff) -> torch.Tensor:\n",
    "    p_hat_ij = F.sigmoid(ri - rj)\n",
    "    rank_loss = torch.mean(- lam_diff @ torch.log(p_hat_ij) - (1 - lam_diff) @ torch.log(1 - p_hat_ij)) / lam_diff.size(0)\n",
    "    return rank_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class StrengthNetMixupLoss(nn.Module):\n",
    "    alpha = 0.1\n",
    "    beta = 1.0\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        predi, predj, y_emo, y_neu, lam_i, lam_j\n",
    "    ):\n",
    "        hi, ri = predi\n",
    "        hj, rj = predj\n",
    "        lam_diff = (lam_i - lam_j) / 2 + 0.5\n",
    "\n",
    "        losses = {}\n",
    "        mixup_loss_i = mixup_criterion(hi, y_emo, y_neu, lam_i)\n",
    "        mixup_loss_j = mixup_criterion(hj, y_emo, y_neu, lam_j)\n",
    "        mixup_loss = mixup_loss_i + mixup_loss_j\n",
    "        losses.update({\n",
    "            \"mi\": mixup_loss_i.item(), \n",
    "            \"mj\": mixup_loss_j.item(),\n",
    "        })\n",
    "        \n",
    "        ranking_loss = rank_loss(ri, rj, lam_diff)\n",
    "        losses.update({\n",
    "            \"rank\": ranking_loss.item(),\n",
    "        })\n",
    "\n",
    "        total_loss = self.alpha * mixup_loss + self.beta * ranking_loss\n",
    "        losses.update({\n",
    "            \"total\": total_loss.item(),\n",
    "        })\n",
    "\n",
    "        return total_loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class RankMixupDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, emo_ids, neu_ids, alpha=1.0):\n",
    "        self.dataset = dataset\n",
    "        self.alpha = alpha\n",
    "        self.emo_ids = emo_ids\n",
    "        self.neu_ids = neu_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_emo = self.dataset[self.emo_ids[np.random.randint(0, len(self.emo_ids))]]\n",
    "        sample_neu = self.dataset[self.neu_ids[np.random.randint(0, len(self.neu_ids))]]\n",
    "\n",
    "        x_emo, y_emo = sample_emo[\"mel\"], sample_emo[\"emotion_id\"]\n",
    "        x_neu, y_neu = sample_neu[\"mel\"], sample_neu[\"emotion_id\"]\n",
    "\n",
    "        x_emo = torch.from_numpy(x_emo).float()\n",
    "        x_neu = torch.from_numpy(x_neu).float()\n",
    "        y_emo = torch.tensor(y_emo, requires_grad=False)\n",
    "        y_neu = torch.tensor(y_neu, requires_grad=False)\n",
    "\n",
    "        return x_emo, x_neu, y_emo, y_neu\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        mel_emo, mel_neu, y_emo, y_neu = zip(*batch)\n",
    "        batch_size = len(mel_neu)\n",
    "        \n",
    "        lam_i = np.random.beta(self.alpha, self.alpha) if self.alpha != 0 else 0\n",
    "        lam_j = np.random.beta(self.alpha, self.alpha) if self.alpha != 0 else 0\n",
    "        if lam_i > 0.5:\n",
    "            lam_i = 1 - lam_i\n",
    "        if lam_j < 0.5:\n",
    "            lam_j = 1 - lam_j\n",
    "        lam_i = [lam_i] * batch_size\n",
    "        lam_j = [lam_j] * batch_size\n",
    "        \n",
    "        xis = []\n",
    "        xjs = []\n",
    "        xi_lens = []\n",
    "        xj_lens = []\n",
    "        for i in range(batch_size):\n",
    "            # if self.rand_lam_per_batch is False:\n",
    "            _lam_i = np.random.beta(self.alpha, self.alpha)\n",
    "            _lam_j = np.random.beta(self.alpha, self.alpha)\n",
    "            lam_i[i] = _lam_i\n",
    "            lam_j[i] = _lam_j\n",
    "            \n",
    "            neu_len = mel_neu[i].shape[0]\n",
    "            emo_len = mel_emo[i].shape[0]\n",
    "            min_mel_len = min(neu_len, emo_len)\n",
    "            neu_start = random.randint(0, neu_len - min_mel_len)\n",
    "            emo_start = random.randint(0, emo_len - min_mel_len)\n",
    "            neu_mel = mel_neu[i][neu_start:neu_start+min_mel_len]\n",
    "            emo_mel = mel_emo[i][emo_start:emo_start+min_mel_len]\n",
    "            xi, _ = mixup_data(emo_mel, neu_mel, lam_i[i])\n",
    "            xj, _ = mixup_data(emo_mel, neu_mel, lam_j[i])\n",
    "            xis.append(xi)\n",
    "            xjs.append(xj)\n",
    "        xi_lens = [len(x) for x in xis]\n",
    "        xj_lens = [len(x) for x in xjs]\n",
    "        max_xi_len = max(xi_lens)\n",
    "        max_xj_len = max(xj_lens)\n",
    "        xi = [F.pad(x, (0, 0, 0, max_xi_len - len(x))) for x in xis]\n",
    "        xj = [F.pad(x, (0, 0, 0, max_xj_len - len(x))) for x in xjs]\n",
    "        xi = torch.stack(xi)\n",
    "        xj = torch.stack(xj)\n",
    "        y_emo = torch.tensor(y_emo, requires_grad=False)\n",
    "        y_neu = torch.tensor(y_neu, requires_grad=False)\n",
    "        lam_i = torch.tensor(lam_i, requires_grad=False)\n",
    "        lam_j = torch.tensor(lam_j, requires_grad=False)\n",
    "\n",
    "        return xi, xj, y_emo, y_neu, lam_i, lam_j, xi_lens, xj_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '0012/Angry/0012_000351.wav',\n",
       " 'score': 0.52011,\n",
       " 'emotion': 'angry',\n",
       " 'emotion_id': 0,\n",
       " 'mel': array([[ -5.891084 ,  -7.9609103,  -6.724277 , ..., -11.107079 ,\n",
       "         -11.025017 , -10.827656 ],\n",
       "        [ -5.492388 ,  -7.182169 ,  -7.0519705, ..., -11.132161 ,\n",
       "         -11.4717655, -11.510298 ],\n",
       "        [ -5.143411 ,  -7.0178847,  -8.056166 , ..., -11.138936 ,\n",
       "         -11.512925 , -11.512925 ],\n",
       "        ...,\n",
       "        [ -5.949753 ,  -7.2775326,  -7.0753965, ..., -11.334373 ,\n",
       "         -11.512925 , -11.512925 ],\n",
       "        [ -5.7215767,  -6.2575912,  -6.301642 , ...,  -9.436365 ,\n",
       "          -9.496191 ,  -9.729062 ],\n",
       "        [ -5.091888 ,  -5.370623 ,  -5.3995743, ...,  -8.487104 ,\n",
       "          -8.542133 ,  -8.772532 ]], dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_ids = train_ds.df[train_ds.df[\"emotion\"] != \"neutral\"].index\n",
    "neu_ids = train_ds.df[train_ds.df[\"emotion\"] == \"neutral\"].index\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_train_ds = RankMixupDataset(train_ds, emo_ids, neu_ids, alpha=1.0)\n",
    "# mix_train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(mix_train_ds, batch_size=4, shuffle=True, collate_fn=mix_train_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 205, 80]) torch.Size([4, 205, 80]) tensor([4, 0, 4, 4]) tensor([2, 2, 2, 2]) tensor([0.8583, 0.6731, 0.4974, 0.7996]) tensor([0.1412, 0.0053, 0.1834, 0.3923]) [148, 182, 205, 169] [148, 182, 205, 169]\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    xi, xj, y_emo, y_neu, lam_i, lam_j, xi_lens, xj_lens = batch\n",
    "    print(xi.shape, xj.shape, y_emo, y_neu, lam_i, lam_j, xi_lens, xj_lens)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_ds.df[\"emotion\"].value_counts()\n",
    "# esd_basedir = \"../datasets/esd_processed\"\n",
    "\n",
    "# lst = []\n",
    "# for f in os.listdir(f\"{esd_basedir}/mel\"):\n",
    "#     if \"neutral\" in f:\n",
    "#         speaker = f.split(\"_\")[1]\n",
    "#         basename = f.split(\"_\")[2]\n",
    "#         emotion = f.split(\"_\")[3].replace(\".pkl\", \"\")\n",
    "#         # build audio path like 0011/Angry/0011_000352.wav\n",
    "#         emotion_upper = emotion[0].upper() + emotion[1:]\n",
    "#         audio_path = f\"{speaker}/{emotion_upper}/{speaker}_{basename}.wav\"\n",
    "#         lst.append({\n",
    "#             \"path\": audio_path,\n",
    "#             \"score\": 0,\n",
    "#         })\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame(lst)\n",
    "# df.to_csv(\"../datasets/ESD_score_list_neu.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(\"../datasets/ESD_score_list.csv\")\n",
    "# df2 = pd.read_csv(\"../datasets/ESD_score_list_neu.csv\")\n",
    "\n",
    "# df1.columns = [\"path\", \"score\"]\n",
    "# df2.columns = [\"path\", \"score\"]\n",
    "\n",
    "# # concat 2 df\n",
    "# df = pd.concat([df1, df2])\n",
    "# df.to_csv(\"../datasets/ESD_score_list_all.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
