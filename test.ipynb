{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 1scuFwqh8s7KIYAfZW1Eu6088ZAK2SI-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ./esd_dataset/Emotion\\ Speech\\ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_DIR = \"./esd_dataset/Emotion Speech Dataset\"\n",
    "\n",
    "import os\n",
    "\n",
    "# os.listdir(DS_DIR + \"/0003\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./esd_dataset/Emotion Speech Dataset/0003/0003.txt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_dict(ds_dir):\n",
    "    d = []\n",
    "    for i, dir in enumerate(os.listdir(ds_dir)):\n",
    "        base_dir = os.path.join(ds_dir, dir)\n",
    "        dic_file = os.path.join(ds_dir, dir, f\"{dir}.txt\")\n",
    "        if os.path.exists(dic_file):\n",
    "            d.append({\n",
    "                \"base_dir\": base_dir,\n",
    "                \"dict_file\": dic_file,\n",
    "            })\n",
    "    return d\n",
    "\n",
    "build_dict(DS_DIR)[0]['dict_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# info = build_dict(DS_DIR)[0]\n",
    "\n",
    "def get_list_files(info):\n",
    "    emotions = ['Happy', 'Sad', 'Surprise', 'Neutral', 'Angry']\n",
    "    list_files = []\n",
    "    for emotion in emotions:\n",
    "        list_files += [os.path.join(info['base_dir'], emotion, f) for f in os.listdir(os.path.join(info['base_dir'], emotion)) if f.endswith(\".wav\")]\n",
    "    return list_files\n",
    "\n",
    "# get_list_files(info)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "\n",
    "for info in build_dict(DS_DIR):\n",
    "    _list_files = get_list_files(info)\n",
    "    list_files += _list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audio as Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "class ESDataset(Dataset):\n",
    "    def __init__(self, list_files):\n",
    "        self.list_files = list_files\n",
    "        self.STFT = Audio.stft.TacotronSTFT(\n",
    "            1024, # config[\"preprocessing\"][\"stft\"][\"filter_length\"],\n",
    "            256, # config[\"preprocessing\"][\"stft\"][\"hop_length\"],\n",
    "            1024, # config[\"preprocessing\"][\"stft\"][\"win_length\"],\n",
    "            80, # config[\"preprocessing\"][\"mel\"][\"n_mel_channels\"],\n",
    "            22050, # config[\"preprocessing\"][\"audio\"][\"sampling_rate\"],\n",
    "            0, # config[\"preprocessing\"][\"mel\"][\"mel_fmin\"],\n",
    "            8000 # config[\"preprocessing\"][\"mel\"][\"mel_fmax\"],\n",
    "        )\n",
    "        self.emo2idx = {\n",
    "            'Neutral': 0,\n",
    "            'Happy': 1,\n",
    "            'Sad': 2,\n",
    "            'Angry': 3,\n",
    "            'Surprise': 4\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        file = self.list_files[idx]\n",
    "        emotion = file.split(\"/\")[-2]\n",
    "        \n",
    "        wav, _ = librosa.load(file, sr=16000)\n",
    "        # convert 16k to 22.05k\n",
    "        wav = librosa.resample(wav, 16000, 22050)        \n",
    "        mel_spectrogram, energy = Audio.tools.get_mel_from_wav(wav, self.STFT)\n",
    "        \n",
    "        return mel_spectrogram.T, emotion, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33484/544894725.py:37: FutureWarning: Pass orig_sr=16000, target_sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  wav = librosa.resample(wav, 16000, 22050)\n"
     ]
    }
   ],
   "source": [
    "dataset = ESDataset(list_files)\n",
    "# dataset.__getitem__(0)[0].shape\n",
    "# dataset.__getitem__(0)[1]\n",
    "# for i in range(12600, 12700):\n",
    "    # dataset.__getitem__(i)[2]\n",
    "# len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./esd_dataset_processed\n",
    "# !mkdir -p ./esd_dataset_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23000 [00:00<?, ?it/s]/tmp/ipykernel_33484/544894725.py:37: FutureWarning: Pass orig_sr=16000, target_sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  wav = librosa.resample(wav, 16000, 22050)\n",
      "100%|██████████| 23000/23000 [27:50<00:00, 13.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "\n",
    "# for sample in dataset:\n",
    "#     mel, emo, file = sample\n",
    "#     file_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "#     pk.dump(mel, open(f\"./esd_dataset_processed/mel_{file_name}_{emo.lower()}.pkl\", \"wb\"))\n",
    "    \n",
    "import multiprocessing as mp\n",
    "import tqdm\n",
    "import pickle as pk\n",
    "\n",
    "def process_sample(sample):\n",
    "    mel, emo, file = sample\n",
    "    if not file.endswith(\".wav\"):\n",
    "        return\n",
    "    file_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    new_file_name = f\"./esd_dataset_processed/mel_{file_name}_{emo.lower()}.pkl\"\n",
    "    if os.path.exists(new_file_name):\n",
    "        return\n",
    "    pk.dump(mel, open(new_file_name, \"wb\"))\n",
    "\n",
    "for idx in tqdm.tqdm(range(12000, len(dataset))):\n",
    "    sample = dataset.__getitem__(idx)\n",
    "    process_sample(sample)\n",
    "\n",
    "# with mp.Pool(8) as pool:\n",
    "#     list(tqdm.tqdm(pool.imap(process_sample, dataset), total=len(dataset)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
