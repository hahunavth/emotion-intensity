{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import read_config\n",
    "from dataset import get_loaders\n",
    "\n",
    "\n",
    "configs = read_config()\n",
    "_, _, _, _, train_set, _ = get_loaders(configs, device=\"cpu\")\n",
    "train_set.alpha=0\n",
    "\n",
    "sad_sample = train_set[0]\n",
    "neutral_sample = train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'speaker', 'text', 'raw_text', 'mel', 'pitch', 'energy', 'duration', 'emotion2id'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005141 | 3 | tôi bắt có làm việc nhà à |\n",
      "008270 | 0 | tôi không thể giúp cô vì anh ta ý cô là sao |\n"
     ]
    }
   ],
   "source": [
    "print(sad_sample['id'], \"|\", \n",
    "      sad_sample['emotion2id'], \"|\",\n",
    "      sad_sample['raw_text'], \"|\",\n",
    ")\n",
    "\n",
    "print(neutral_sample['id'], \"|\", \n",
    "      neutral_sample['emotion2id'], \"|\",\n",
    "      neutral_sample['raw_text'], \"|\",\n",
    ")\n",
    "import torch\n",
    "mel = torch.from_numpy(neutral_sample['mel']).T\n",
    "# mel to audio:\n",
    "#\n",
    "# import librosa\n",
    "# S = librosa.feature.inverse.mel_to_stft(mel)\n",
    "# y = librosa.griffinlim(S)\n",
    "\n",
    "# from IPython.display import Audio\n",
    "# Audio(y, rate=16000)\n",
    "\n",
    "STFT = Audio.stft.TacotronSTFT(\n",
    "            1024, # config[\"preprocessing\"][\"stft\"][\"filter_length\"],\n",
    "            256, # config[\"preprocessing\"][\"stft\"][\"hop_length\"],\n",
    "            1024, # config[\"preprocessing\"][\"stft\"][\"win_length\"],\n",
    "            80, # config[\"preprocessing\"][\"mel\"][\"n_mel_channels\"],\n",
    "            22050, # config[\"preprocessing\"][\"audio\"][\"sampling_rate\"],\n",
    "            0, # config[\"preprocessing\"][\"mel\"][\"mel_fmin\"],\n",
    "            8000 # config[\"preprocessing\"][\"mel\"][\"mel_fmax\"],\n",
    "        )\n",
    "STFT._stft_fn = STFT.stft_fn # hotfix\n",
    "import audio as Audio\n",
    "Audio.tools.inv_mel_spec(mel, \"neu.wav\", STFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import mixup_data\n",
    "\n",
    "emo_mel = sad_sample['mel']\n",
    "neu_mel = neutral_sample['mel']\n",
    "\n",
    "min_len = min(emo_mel.shape[0], neu_mel.shape[0])\n",
    "emo_mel = emo_mel[:min_len]\n",
    "neu_mel = neu_mel[:min_len]\n",
    "\n",
    "mixup_mel, lam = mixup_data(emo_mel, neu_mel, lam=0.6)\n",
    "mixup_mel = torch.from_numpy(mixup_mel).T\n",
    "Audio.tools.inv_mel_spec(mixup_mel, \"mix-lamb=0.6.wav\", STFT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
